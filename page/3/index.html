<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Wens'Blog - 将欲取之，必先与之。</title><meta name="author" content="Wens"><meta name="copyright" content="Wens"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta property="og:type" content="website">
<meta property="og:title" content="Wens&#39;Blog">
<meta property="og:url" content="http://reveryday.github.io/page/3/index.html">
<meta property="og:site_name" content="Wens&#39;Blog">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://reveryday.github.io/images/wens.png">
<meta property="article:author" content="Wens">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://reveryday.github.io/images/wens.png"><link rel="shortcut icon" href="/images/logo.png"><link rel="canonical" href="http://reveryday.github.io/page/3/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><meta/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"prismjs","highlightCopy":false,"highlightLang":false,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Wens\'Blog',
  isHighlightShrink: undefined,
  isToc: false,
  pageType: 'home'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/images/wens.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">32</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">10</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">4</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user-circle"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Friends</span></a></div></div></div></div><div class="page" id="body-wrap"><header class="full_page" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user-circle"></i><span> About</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Friends</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="site-info"><h1 id="site-title">Wens'Blog</h1><div id="site-subtitle"><span id="subtitle"></span></div></div><div id="scroll-down"><i class="fas fa-angle-down scroll-down-effects"></i></div></header><main class="layout hide-aside" id="content-inner"><div class="recent-posts nc" id="recent-posts"><div class="recent-post-items"><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/03/16/DL6-rnn/" title="DL6-recurrent-neural-networks">DL6-recurrent-neural-networks</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-03-16T13:24:03.000Z" title="发表于 2025-03-16 21:24:03">2025-03-16</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Deep-Learning-PyTorch/">Deep Learning-PyTorch</a></span></div><div class="content">到目前为止我们默认数据都来自于某种分布， 并且所有样本都是独立同分布的，大多数的数据并非如此，且我们不仅仅需要接收一个序列作为输入，而是还期望继续猜测这个序列的后续。  CNN可以有效处理空间信息，RNN可以处理时间信息，或者样本之间并非独立同分布的数据。  卷积神经网络可以有效地处理空间信息， 那么循环神经网络（RNN）则可以更好地处理序列信息，通过引入状态变量存储过去的信息和当前的输入，从而可以确定当前的输出。 自回归模型   $t &gt; \tau$时，用观测序列$x_{t-1}, \ldots, x_{t-\tau}$$x_{\tau}$预测当下，参数的数量不变，这种模型被称为自回归模型，因为它们是对自己执行回归   2. 保留一些对过去观测的总结$h_t$，同时更新预测$\hat{x}_t$和总结$h_t$，基于$\hat{x}_t = P(x_t \mid h_{t})$估计$x_t$，以及公式$h_t = g(h_{t-1}, x_{t-1})$更新的模型，由于$h_t$未被观测到，这类模型称为**隐变量自回归模型**    ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/03/16/DL5-conv-modern/" title="DL5-conv-modern">DL5-conv-modern</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-03-16T08:58:42.000Z" title="发表于 2025-03-16 16:58:42">2025-03-16</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Deep-Learning-PyTorch/">Deep Learning-PyTorch</a></span></div><div class="content">AlexNet 训练神经网络的一些关键技巧：（1）启发式参数初始化、（2）随机梯度下降的变体、（3）非挤压激活函数和（4）有效的正则化技术。  从对最终模型精度的影响来说，更大或更干净的数据集、或是稍微改进的特征提取，比任何学习算法带来的进步要大得多。   AlexNet通过暂退法控制全连接层的模型复杂度，而LeNet只使用了权重衰减。为了进一步扩充数据，AlexNet在训练时增加了大量的图像增强数据，如翻转、裁切和变色，这使得模型更健壮，更大的样本量有效地减少了过拟合。 VGG 使用块的想法首先出现在VGG网络中，通过使用循环和子程序：  NIN LeNet、AlexNet和VGG都有一个共同的设计模式：通过一系列的卷积层与汇聚层来提取空间结构特征，然后通过FCNN对特征的表征进行处理。 AlexNet和VGG对LeNet的改进主要在于如何扩大和加深这两个模块。然而，使用了FCNN，可能会完全放弃特征的空间结构，NiN提供了一个非常简单的解决方案：在每个像素的通道上分别使用多层感知机。 GoogLeNet GoogLeNet吸收了NiN中串联网络的思想，并在此基础上做了改进。...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/03/03/DL4-conv%20elements/" title="DL4-Conv Elements">DL4-Conv Elements</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-03-03T13:38:03.000Z" title="发表于 2025-03-03 21:38:03">2025-03-03</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Deep-Learning-PyTorch/">Deep Learning-PyTorch</a></span></div><div class="content">卷积层的输入与输出：输入形状为$n_h\times n_w$，卷积核形状为$k_h\times k_w$，那么输出形状将是$(n_h-k_h+1) \times...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/03/01/MCNP-input-output/" title="MCNP-input-output">MCNP-input-output</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-03-01T07:19:26.000Z" title="发表于 2025-03-01 15:19:26">2025-03-01</time></span></div><div class="content">运行一个case会产生80个数据点，输出80组数据，case10.50 MeV 4 Layers 10.0 Con 11.0 Pb 4.5 Fe 14.5 Con 自动化脚本提取结果： （1是考虑外侧反射层的结果，2是使用标记记数不考虑外侧介质反射的结果）             屏蔽层数                                                              注量 flux      照射量exposure  有效剂量effective dose ENERGY   N M1  MFP1 M2  MFP2 M3  MFP3 M4  MFP4  FLU-BUF-1     EXP-BUF-1     EFF-BUF-T1    FLU-BUF-T2    EXP-BUF-T2    EFF-BUF-T2 5.00E-01 1 Con  0.5      0.0      0.0      0.0  2.456262E+00  1.559544E+00  1.563126E+00  1.788371E+00 ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/03/01/MCNP-Manual/" title="MCNP Manual">MCNP Manual</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-03-01T07:01:15.000Z" title="发表于 2025-03-01 15:01:15">2025-03-01</time></span></div><div class="content">Input Card Tally Card  Simple Data-card Form: Fn:P s1 : : : sK or General Data-card Form: Fn:P s1 (s2 : : : s3) (s4 : : : s5) s6 s7 : : : [T]    n Tally number. Restriction: n  99999999     P Particle designator   sk Problem number of surface or cell for tallying   T Total over specified surfaces for F1 tallies; average over specified surfaces or cells for F2 , F4 , F6 , and F7 tallies. (Optional)    WWE  WWG: Weight-window Generation   WWG 802 1 0 J J J J 0 - 这是一个权重窗口生成卡，用于 802 号记数 wwe:p...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/02/28/DL3-cnn/" title="DL3-Convolutional Neural Network">DL3-Convolutional Neural Network</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-02-28T08:28:53.000Z" title="发表于 2025-02-28 16:28:53">2025-02-28</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Deep-Learning-PyTorch/">Deep Learning-PyTorch</a></span></div><div class="content">Why Conv 仅仅通过将图像数据展平成一维向量而忽略了每个图像的空间结构信息，MLP十分适合处理表格数据，其中行对应样本，列对应特征。 对于表格数据，我们寻找的模式可能涉及特征之间的交互，但是我们不能预先假设任何与特征交互相关的先验结构。所以处理表格数据，多层感知机可能是最好的选择，然而对于高维感知数据，这种缺少结构的网络可能会变得不实用。 卷积层的特有能力——在高度和宽度维度上，识别相邻元素间相互作用的能力。 从全连接到卷积 在图片里找模式的原则：  空间不变性：使用较少的参数来学习有用的表示 局部性（只取决于附近的元素）  将这两个原则作为启发，从全连接层得到卷积。首先，将输入与输出变形为矩阵，则权重变形为4-D张量，输入输出为向量时： $$ h_{i}=\sum_{j}^{} w_{i,j}x_{j} $$ 当输入输出为矩阵时： $$ h_{i,j}=\sum_{k,l}^{} w_{i,j,k,l}x_{k,l} $$ 对x进行重新索引，$v_{i,j,a,b}=w_{a,b}$，则 $$ h_{i,j}=\sum_{k,l}^{}...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/02/21/%CE%B3%E8%BE%90%E5%B0%84%E5%9C%BA%E8%AE%A1%E7%AE%97/" title="γ辐射场计算">γ辐射场计算</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-02-21T05:44:01.000Z" title="发表于 2025-02-21 13:44:01">2025-02-21</time></span></div><div class="content">常用辐射量 粒子注量：单位面积粒子数 $$ \Phi =\frac{dN}{da}particles/m^{2} $$ 能量注量：单位面积粒子总动能 $$ \Psi =\frac{dE}{dm} J/m^{2} $$ 吸收剂量：单位面积吸收的辐射能量（拉德rad为专属单位） $$ D=\frac{d\xi }{dm} J/Kg $$ 吸收剂量率： $$ \dot{D} =\frac{dD }{dt} Gy/s $$ 其中$1J/Kg=1Gy=100rad$. 为了量度不同核辐射引发生物效应的不同，制定对人的核辐射防护标准，引入品质因子$Q$，定义为吸收介质的单位路径上核辐射沉积能量的多少。剂量当量定义为：生物体对辐射的吸收剂量$D$和该辐射的品质因子$Q$的乘积： $$ H=D \cdot Q $$ 其国际单位制单位为$J/Kg$，专名为希沃特（Sv, sievent）。 比释动能：粒子与物质作用时在单位质量物质上产生次级带电粒子总动能 $$ K=\frac{dE_{tr} }{dm} J/Kg $$ 比释动能率： $$ \dot{K} =\frac{dK }{dt}...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/02/09/Hexo%20Blog/" title="Hexo Blog">Hexo Blog</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-02-09T13:53:10.000Z" title="发表于 2025-02-09 21:53:10">2025-02-09</time></span></div><div class="content">博客搭建： （搭建指令皆在git bash中完成） 1、安装Git，安装好后检查版本信息： $ git --version git version 2.47.1.windows.2 2、安装nodejs（Hexo是基于nodejs编写的，需安装nodejs和里面的npm工具， npm会随Node.js一起安装），安装好后需将npm的全局包路径需要添加到系统的 PATH 环境变量中（通常为：C:\Users\用户名\AppData\Roaming\npm），再检查版本信息： $ node -v v22.13.0 $ npm -v 10.9.2 3、安装hexo，全局安装： $ npm install -g hexo-cli 初始化： $ hexo init Blog $ npm install  up to date in 1s  24 packages are looking for funding   run `npm fund` for details $ ls _config.landscape.yml  db.json    node_modules/     ...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/02/09/DL2-Linear%20Neteorks&amp;mlp/" title="DL2-Linear Networks &amp; MLP">DL2-Linear Networks &amp; MLP</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-02-09T07:57:51.000Z" title="发表于 2025-02-09 15:57:51">2025-02-09</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Deep-Learning-PyTorch/">Deep Learning-PyTorch</a></span></div><div class="content">Scratch   1、生成数据集 - 根据带有噪声的线性模型构造一个人造数据集 def synthetic_data(w, b, num_examples):      """生成y=Xw+b+噪声"""     X = torch.normal(0, 1, (num_examples, len(w)))     y = torch.matmul(X, w) + b     y += torch.normal(0, 0.01, y.shape)     return X, y.reshape((-1, 1))      true_w = torch.tensor([2, -3.4]) true_b = 4.2 features, labels = synthetic_data(true_w, true_b, 1000) 其中：torch.normal(mean, std, size)：生成 N(mean, std^2) （正态）分布的随机数 2、读取数据集 - 每次抽取一小批量样本，对数据集进行遍历 def data_iter(batch_size, features,...</div></div></div><div class="recent-post-item"><div class="recent-post-info no-cover"><a class="article-title" href="/2025/02/08/DL1-introduction/" title="DL1-Introduction">DL1-Introduction</a><div class="article-meta-wrap"><span class="post-meta-date"><i class="far fa-calendar-alt"></i><span class="article-meta-label">发表于</span><time datetime="2025-02-08T06:53:45.000Z" title="发表于 2025-02-08 14:53:45">2025-02-08</time></span><span class="article-meta"><span class="article-meta-separator">|</span><i class="fas fa-inbox"></i><a class="article-meta__categories" href="/categories/Deep-Learning-PyTorch/">Deep Learning-PyTorch</a></span></div><div class="content">Introduction Supervised Learning（监督学习）：  在神经网络上获得更好的性能，往往就是：  训练一个更大的神经网络 投入更多的数据  Basics  Activation Function   最简单的激活函数：         $$    \sigma (x)=\left\{\begin{matrix}1\quad if \quad x>0     \\0\quad otherwise        \end{matrix}\right.    $$        sigmoid函数：  $$ sigmoid(x)=\frac{1}{1+e^{-x} } $$  Tanh激活函数：  $$ tanh(x)=\frac{1-e^{-2x}}{1+e^{-2x}} $$  ReLU激活函数（最常用，计算速度快）：  $$ ReLU(x)=max(x,0) $$   ...</div></div></div></div><nav id="pagination"><div class="pagination"><a class="extend prev" rel="prev" href="/page/2/#content-inner"><i class="fas fa-chevron-left fa-fw"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/#content-inner">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/#content-inner">4</a><a class="extend next" rel="next" href="/page/4/#content-inner"><i class="fas fa-chevron-right fa-fw"></i></a></div></nav></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2025 By Wens</div><div class="footer_custom_text">天道酬勤</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"></div><div id="rightside-config-show"><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>window.typedJSFn = {
  init: str => {
    window.typed = new Typed('#subtitle', Object.assign({
      strings: str,
      startDelay: 300,
      typeSpeed: 150,
      loop: true,
      backSpeed: 50,
    }, null))
  },
  run: subtitleType => {
    if (true) {
      if (typeof Typed === 'function') {
        subtitleType()
      } else {
        btf.getScript('https://cdn.jsdelivr.net/npm/typed.js/dist/typed.umd.min.js').then(subtitleType)
      }
    } else {
      subtitleType()
    }
  }
}
btf.addGlobalFn('pjaxSendOnce', () => { typed.destroy() }, 'typedDestroy')
</script><script>function subtitleType () {
  if (true) {
    typedJSFn.init(["将欲取之，必先与之。"])
  } else {
    document.getElementById("subtitle").textContent = "将欲取之，必先与之。"
  }
}
typedJSFn.run(subtitleType)</script></div></div></body></html>